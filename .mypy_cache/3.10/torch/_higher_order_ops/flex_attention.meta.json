{"data_mtime":1765103358,"dep_hashes":["255190d0397728528b1e891a18ad4d75ead072af","74d75e8c6fcb7524fa63a66d26e0768a514ac21a","2feec53ce2674d115d43b6b231ab7b9f0c2f23ad","8014d3b6fe1f1dee98deb44d42076f644ed28977","cf3046de10524f90aff6daae578147691661bb2a","3a94bdd3dec77bcbc6520a27e2d81e5f052e6ece","9243ad8a06a19f8e3546a0af1c7a8e5f4813a3b0","3ac356a8f7e9d5f76992bfd4502060f7dc754107","1da2be66584e34ae918a47522bcf8a77b3d00863","2f29669b5501392b027f5f0ec1d6b3bc8eb85399","9429f2a065db7baf26aadf85118ae1676f9452da","5f829e702843382242af467f31a206826a0a6e68","a9891168dba2359b1fecb2706e4dce329237489e","3aabfe837b97752382a667fdfba14712e70f41bd","689da38eddf34bf673da351462a7ff4c511811a1","5a0057cbc1d6aa96feb94923c13a6445b69d5723","08934eb58468268b38a12b84ddde76c20c760429","de6310a0128fea19631b7ae9339ec80c6c3a95d2","fd4bb73fb26fbc9678e13ebdf06578cfe10c263e","c37c7cb1a12474444cfeaee3f1d0fa3c626e4a65","863fc1fa4bf2ce2fe25d3e0705165a9c8a0b150b","7c70ca7033e96e0f392df57337b551f01c6c7221","d9f85670de302dd915fb7a006412a619af61e052","0b8774b249f514938e8ac9769b67698f257e562e","7e365025491a129f6287241384c3ee13a7d49543"],"dep_lines":[25,6,9,24,30,31,2,6,8,22,23,1,3,5,1,1,1,1,1,1,1,1,1,1,1],"dep_prios":[5,10,5,5,5,5,5,20,5,5,5,10,5,5,5,30,30,30,30,30,30,30,30,30,30],"dependencies":["torch.fx.experimental.proxy_tensor","torch.utils._pytree","torch._higher_order_ops.utils","torch._subclasses.functional_tensor","torch.fx.graph_module","torch.utils.checkpoint","collections.abc","torch.utils","torch._C","torch._ops","torch._subclasses","math","typing","torch","builtins","abc","enum","torch._C._functorch","torch._tensor","torch.autograd","torch.autograd.function","torch.fx._symbolic_trace","torch.fx.proxy","torch.nn.modules.module","torch.utils._python_dispatch"],"error_lines":[],"hash":"dc5284d1fffda380685541b945c3c8e256320fda","id":"torch._higher_order_ops.flex_attention","ignore_all":true,"interface_hash":"6ce5bb77508f5644cbde866b6b19a652276bb026","mtime":1763653745,"options":{"other_options":"d8641727149548a69732ead80521eaf9086cd355","platform":"darwin"},"path":"/opt/homebrew/anaconda3/lib/python3.10/site-packages/torch/_higher_order_ops/flex_attention.py","plugin_data":null,"size":44175,"suppressed":[],"version_id":"1.19.0"}